
# Setting up the IPython notebook
**Import pandas, Numpy and datetime** 
```{python}
 import numpy as np 
 ```
 ```{python}
 import pandas as pd 
 ```
 ```{python}
 import datetime
 ```
 **Set some pandas options for controlling output** 
 ```{python}
 pd.set_option('display.notebook_repr_html', False)
 ```
 ```{python}
  pd.set_option('display.max_columns', 10)
 ```
 ```{python}
  pd.set_option('display.max_rows', 10)
 ```

# Working with missing data
**create a DataFrame with 5 rows and 3 columns** 
 ```{python}
 df = pd.DataFrame(np.arange(0, 15).reshape(5, 3),  
 index=['a', 'b', 'c', 'd', 'e'],  
 columns=['c1', 'c2', 'c3']) 
 df 
 ```

**add some columns and rows to the DataFrame** 
**column c4 with NaN values** 
```{python}
 df['c4'] = np.nan
 ```

**row 'f' with 15 through 18**
  ```{python}
 df.loc['f'] = np.arange(15, 19)
 ```

**row 'g' will all NaN**
 ```{python}
 df.loc['g'] = np.nan
 ```

**column 'C5' with NaN's**
 ```{python}
 df['c5'] = np.nan
 ```

**change value in col 'c4' row 'a'**
 ```{python}
 df.loc['a', 'c4'] = 20 #aquí es donde pasa el error, se solucionó  agregando .loc
 df
 ```

 # Determining NaN values in Series and  DataFrame objects 
**which items are NaN?** 
```{python}
 df.isnull() 
 ```
**count the number of NaN values in each column**
```{python}
 df.isnull().sum()
 ```

 **total count of NaN values**
 ```{python}
 df.isnull().sum().sum()
 ```
 **number of non-NaN values in each column**
 ```{python}
 df.count()
 ```
 **and this counts the number of NaN values too**
 ```{python}
 (len(df) - df.count()).sum()
 ```
**which items are not null?**
 ```{python}
 df.notnull()
 ```
 # Selecting out or dropping missing data
 **select the non-NaN items in column c4**
 ```{python}
 df.c4[df.c4.notnull()]
 ```
 **dropna will also return non NaN values**
 **this gets all non NaN items in column c4**
 ```{python}
  df.c4.dropna() 
 ```
 **dropna returns a copy with the values dropped**
 **the source DataFrame / column is not changed**
 ```{python}
 df.c4
 ```
 **on a DataFrame this will drop entire rows where there is at least one NaN, in this case, that is all rows**
 ```{python}
 df.dropna()
 ```
 **using how='all', only rows that have all values as NaN will be dropped**
 ```{python}
 df.dropna(how = 'all')
 ```
**flip to drop columns instead of rows**
```{python}
 df.dropna(how='all', axis=1) # say goodbye to c5
 ```
**make a copy of df**
```{python}
 df2 = df.copy()
 ```
**replace two NaN cells with values** # Lo estoy cambiando por un 5
 ```{python}
 df.loc['g','c1' ] = 0 
 df.loc['g','c3' ] = 0 
 #acá tambien dió error, se cambió df2.ix['g'].c1 por df.loc['g','c1' ]
 ```
 ```{python}
print(df)
 ```
**now drop columns with any NaN values**
```{python}
 df2.dropna(how='any', axis=1)
 ```
**only drop columns with at least 5 NaN values**
```{python}
 df.dropna(thresh=5, axis=1)
 ```
# How pandas handles NaN values in  mathematical operations
**create a NumPy array with one NaN value** 
```{python}
 a = np.array([1, 2, np.nan, 3])
 ```
**create a Series from the array** 
 ```{python}
 s = pd.Series(a) 
 ```
**the mean of each is different**
```{python}
  a.mean(), s.mean()
 ```
 **demonstrate sum, mean and cumsum handling of NaN** 
 **get one column:**
 ```{python}
  s = df.c4
  s.sum() # NaN values treated as 0
 ```
```{python}
 s.mean() # NaN also treated as 0 
 ```
 **as 0 in the cumsum, but NaN values preserved in result Series**
```{python}
 s.cumsum()
 ```
 **# in arithmetic, a NaN value will result in NaN**
```{python}
 df.c4 + 1
 ```
# Filling in missing data
**return a new DataFrame with NaN values filled with 0**
```{python}
 filled = df.fillna(0)
 filled
 ```
**NaNs don't count as an item in calculating # the means**
 ```{python}
 df.mean()
 ```
**having replaced NaN with 0 can make operations such as mean have different results**
 ```{python}
 filled.mean()
 ```
**only fills the first two NaN values in each row with 0**
```{python}
 df.fillna(0, limit=2)
 ```
# Forward and backward flling of missing  values
**extract the c4 column and fill NaNs forward** 
```{python}
 df.c4.fillna(method="ffill")
 ```
**perform a backwards fill** 
```{python}
df.c4.fillna(method="bfill")
 ```
# Filling using index labels
**create a new Series of values to be used to fill NaN values where the index label matches**
```{python}
 fill_values = pd.Series([100, 101, 102], index=['a', 'e', 'g'])  
 fill_values
 ```
**using c4, fill using fill_values a, e and g will be filled with matching values** 
```{python}
 df.c4.fillna(fill_values)
 ```
**fill NaN values in each column with the mean of the values in that column** 
```{python}
 df.fillna(df.mean())
 ```
# Interpolation of missing values 
**linear interpolate the NaN values from 1 through 2**
```{python}
s = pd.Series([1, np.nan, np.nan, np.nan, 2]) 
s.interpolate()
 ```

**create a time series, but missing one date in the Series**
```{python}
 ts = pd.Series([1, np.nan, 2],  
 index=[datetime.datetime(2014, 1, 1),  
 datetime.datetime(2014, 2, 1),  
 datetime.datetime(2014, 4, 1)]) 
 ts 
```
**linear interpolate based on the number of items in the Series**
 ```{python}
  ts.interpolate() 
```
**this accounts for the fact that we don't have an entry for 2014-03-01** 
```{python}
  ts.interpolate(method="time") 
 ```
** a Series to demonstrate index label based interpolation**
```{python}
 s = pd.Series([0, np.nan, 100], index=[0, 1, 10]) 
 s
 ```
**linear interpolate** 
```{python}
  s.interpolate()
 ```
**interpolate based upon the values in the index** 
```{python}
  s.interpolate(method="values") 
 ```

# Handling duplicate data
**a DataFrame with lots of duplicate data**
```{python}
 data = pd.DataFrame({'a': ['x'] * 3 + ['y'] * 4,  
 'b': [1, 1, 2, 3, 3, 4, 4]}) 
 data
 ```
**reports which rows are duplicates based upon if the data in all columns was seen before** 
 ```{python}
 data.duplicated()
 ```
**drop duplicate rows retaining first row of the duplicates**
```{python}
 data.drop_duplicates()
 ```
**drop duplicate rows, only keeping the first instance of any data** 
```{python}
 #data.drop_duplicates(take_last=True) da error,'take_last' argument was deprecated and removed in newer versions of pandas. Remplazo por:
 data.drop_duplicates(keep='last')
 ```
**add a column c with values 0..6 this makes .duplicated() report no duplicate rows**
 ```{python}
 data['c'] = range(7)
 data.duplicated() 
 ```
**but if we specify duplicates to be dropped only in columns a & b they will be dropped**
 ```{python}
  data.drop_duplicates(['a', 'b'])
 ```
# Mapping 
**create two Series objects to demonstrate mapping**
```{python}
 x = pd.Series({"one": 1, "two": 2, "three": 3}) 
 y = pd.Series({1: "a", 2: "b", 3: "c"}) 
 x
 ```
```{python}
 y
 ```
**map values in x to values in y** 
```{python}
 x.map(y)
 ```
**three in x will not align / map to a value in y** 
```{python}
 x = pd.Series({"one": 1, "two": 2, "three": 3}) 
 y = pd.Series({1: "a", 2: "b"}) 
 x.map(y) 
 ```
# Replacing values
**create a Series to demonstrate replace**
```{python}
 s = pd.Series([0., 1., 2., 3., 2., 4.]) 
 s
 ``` 
**replace all items with index label 2 with value 5**
```{python}
  s.replace(2, 5)
 ```
 **replace all items with new values** 
 ```{python}
  s.replace([0, 1, 2, 3, 4], [4, 3, 2, 1, 0])
 ```
**replace using entries in a dictionary** 
```{python}
 s.replace({0: 10, 1: 100})
 ```
**DataFrame with two columns**
```{python}
df = pd.DataFrame({'a': [0, 1, 2, 3, 4], 'b': [5, 6, 7, 8, 9]})
print(df)
 ```
 **specify different replacement values for each column**
 ```{python}
  df.replace({'a': 1, 'b': 8}, 100)
 ```
**demonstrate replacement with pad method set first item to 10, to have a distinct replacement value**
```{python}
 s[0] = 10
 s
 ```
**replace items with index label 1, 2, 3, using fill from the most recent value prior to the specified labels (10)**
```{python}
 s.replace([1, 2, 3], method='pad') #Recibí este warning:The 'method' keyword in Series.replace is deprecated and will be removed in a future version. FYI
 ```
# Applying functions to transform data
**demonstrate applying a function to every item of a Series**
```{python}
  s = pd.Series(np.arange(0, 5)) 
  s.apply(lambda v: v * 2)
 ```
**demonstrate applying a sum on each column**
```{python}
 df = pd.DataFrame(np.arange(12).reshape(4, 3),  
 columns=['a', 'b', 'c']) 
 df
 ```
**calculate cumulative sum of items in each column**
```{python}
 df.apply(lambda col: col.sum())
 ```
**calculate the sum of items in each row**
```{python}
  df.apply(lambda row: row.sum(), axis=1)
 ```

**create a new column 'interim' with a * b**
```{python}
 df['interim'] = df.apply(lambda r: r.a * r.b, axis=1)  
 df
 ```
**and now a 'result' column with 'interim' + 'c'**
 ```{python}
 df['result'] = df.apply(lambda r: r.interim + r.c, axis=1)  
 df
 ```
**replace column a with the sum of columns a, b and c**
```{python}
df.a = df.a + df.b + df.c
df
 ```
**create a 3x5 DataFrame only second row has a NaN**
```{python}
 df = pd.DataFrame(np.arange(0, 15).reshape(3,5)) 
 df.loc[1, 2] = np.nan 
 df
 ```
**demonstrate applying a function to only rows having  # a count of 0 NaN values** 
 ```{python}
 df.dropna().apply(lambda x: x.sum(), axis=1)
 ```
**use applymap to format all items of the DataFrame** 
```{python}
 df.applymap(lambda x: '%.2f' % x) #FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.df.applymap(lambda x: '%.2f' % x. FYI profe ☺
 ```
 


  

  









 